{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6bLSgXhBp_ik",
        "0qdP0X3Op_il",
        "0HMdK4nwp_in",
        "Q_5QUDc8p_io",
        "JWyNFYd7p_iq",
        "bnj-EyYPp_ir",
        "TDcdMxXLp_iu",
        "xORrcb8ap_iv",
        "XzQ3Q5Trp_iv",
        "oZGXRCNrlBde"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasyl808/NULP_NLP/blob/main/LPNLP_Workbook_3_Word_embeddings_for_classification_(2024).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiiDM1V8p_iX"
      },
      "source": [
        "# Workbook 03: Word embeddings for text classification\n",
        "\n",
        "У цій роботі ми використаємо word embeddings для тренування моделі класифікації текстів.\n",
        "\n",
        "Маємо побачити, як word embeddings особливо сильно допомогають, коли тренувальних даних небагато (а їх майже завжди небагато)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --ignore-installed http://nlp.band/static/pypy/lpnlp-2023.10.2-py3-none-any.whl"
      ],
      "metadata": {
        "id": "zBBM2S6_jI8r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3BcrrZzDGZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c6d3aa-9eee-489e-c1e7-530fa53f3e1c"
      },
      "source": [
        "import lpnlp\n",
        "lab = lpnlp.start(\n",
        "    email=\"vasyl.hunia.kn.2021@lpnu.ua\",  # <---------------------- Заповніть це поле\n",
        "    lab=\"using_word_embeddings\",\n",
        ")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Удачі!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdb5yxDGp_ig"
      },
      "source": [
        "# GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZQ5JifvDp_ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4a4d77-b582-4d47-a161-01ba07230749"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KESE75BDp_ih"
      },
      "source": [
        "Повний GloVe містить 4,000,000 векторів і займає багато пам'яті. Щоб уникнути проблем з пам'ятю, залишимо лише 50,000 векторів найчастотніших слів. Це трохи знизить якість моделей, але це зараз не головне."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSPkhqoep_ih"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "glove = KeyedVectors.load(\"http://nlp.band/static/files/glove-50k.bin\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC899YNmp_ir"
      },
      "source": [
        "# Bag-of-embeddings\n",
        "\n",
        "Вектори слів, натреновані на великому корпусі текстів, використовують для представлення слів замість розріджених one-hot, які ми бачили в першій лабораторній. Word embeddings чудово працюють з нейронним мережами різноманітних архітектур. Але зараз ми розглянемо напростіше використання: логістичну регресію (так, знову) та мішок векторів (bag-of-embeddings).\n",
        "\n",
        "В bag-of-embeddings ми усереднюємо вектори всіх слів, які входять в речення. Результат — вектор такої ж розмірності, як і вектор слова. Цей вектор кодує зміст усього речення. Звичайно, таке представлення не враховує порядок слів, рівноцінно ставиться до важливих та допоміжних слів, а тому \"кодує\" воно зміст речення вельми приблизно. Проте цього достатньо для багатьох простих задач."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnj-EyYPp_ir"
      },
      "source": [
        "## Токенізація\n",
        "\n",
        "Для початку нам треба токенізувати корпус. Важливий момент: GloVe та інші word embeddings тренувалися кожен зі своїм токенізатором. Нам слід використовувати максимально схожий токенізатор. Інакше ми не зможемо знайти вектори для багатьох слів.\n",
        "\n",
        "Насамперед, GloVe тренувалися на тексті, приведеному до нижнього регістру. Також розбіжності можуть бути в кодуванні слів типу `I'll` (токенізується в два токени `I 'll` чи в один токен `I'll`?), `don't`, `I've` і подібних.\n",
        "\n",
        "Перевіримо, який варіант токенізації використовує GloVe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwSeYexXp_is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcadb1bc-c72c-49ba-b757-22935fb60755"
      },
      "source": [
        "\"don't\" in glove"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7PLcDlop_is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1529a9-4dd3-459f-a7dd-2e1663b82d69"
      },
      "source": [
        "\"n't\" in glove"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InXjt_Oap_is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d55c142-b535-463c-c0b5-dda12922d177"
      },
      "source": [
        "\"I'll\" in glove"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIGf6CMdp_it",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416a3158-decf-4461-92e1-4215e279f318"
      },
      "source": [
        "\"'ll\" in glove"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Zyzasep_it"
      },
      "source": [
        "Отже, маємо розбивати `don't` на два токени: `do` + `n't`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8pkOJMrp_it",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ef17ff-bfd8-43c2-b3e3-7c43e416f909"
      },
      "source": [
        "import spacy\n",
        "from typing import List\n",
        "\n",
        "\n",
        "spacy_nlp = spacy.blank(\"en\")\n",
        "\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "  \"\"\"Tokenize string with SpaCy. \"\"\"\n",
        "\n",
        "  tokens = spacy_nlp.tokenizer(text)\n",
        "  return [str(token).lower() for token in tokens]\n",
        "\n",
        "tokenize(\"I don't know\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'do', \"n't\", 'know']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDcdMxXLp_iu"
      },
      "source": [
        "## Векторизація одного документа\n",
        "\n",
        "Тепер можемо порахувати вектор для кожного документу в корпус. Цей вектор буде дорівнювати середньому від векторів окремих слів документа."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLbkwgWdp_iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f067ff3-33a9-4e01-bfc4-bf86588279bb"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "def bag_of_embeddings(doc: str, embeddings: KeyedVectors) -> np.ndarray:\n",
        "    tokens = tokenize(doc)\n",
        "\n",
        "    ##################################################\n",
        "    doc_vector = np.array([\n",
        "        embeddings[token]\n",
        "        for token in tokens\n",
        "        if token in embeddings\n",
        "    ]).mean(axis=0)              # <------------------- ваш код\n",
        "    ##################################################\n",
        "\n",
        "    return doc_vector\n",
        "\n",
        "\n",
        "doc_embedding = bag_of_embeddings(\"Hello world!\", glove)\n",
        "print(f\"Embedding: {doc_embedding}\")\n",
        "print(f\"Shape:     {doc_embedding.shape}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding: [ 0.41084     0.4957     -0.35982665 -0.40393332 -0.19768667  0.25433\n",
            " -0.51489997  0.086394    0.04418867  0.365309   -0.3562367   0.15675335\n",
            "  0.09240001  0.4017      0.00335334 -0.08881667 -0.37311664  0.5704167\n",
            "  0.04311933  0.34267667  0.47882667  1.489306    0.25857666 -0.19864707\n",
            "  0.10432333  0.125766    0.10343501 -0.28578332 -0.31660533  0.013828\n",
            " -0.07466667  0.13855    -0.32214698 -0.28048036 -0.41403     0.06308667\n",
            " -0.239556   -0.03680335 -0.141137   -0.0916     -0.16916066  0.5716353\n",
            " -0.3125367   0.07347333 -0.16953166  0.20232     0.60658664  0.06445\n",
            " -0.01957001  0.30074     0.21663667 -0.06867133  0.4030467   0.07233366\n",
            " -0.17247333  0.20601167 -0.39144    -0.02245933 -0.17295867 -0.19998033\n",
            "  0.234197   -0.29320666 -0.13344    -0.1644     -0.00662334  0.01097\n",
            " -0.00953534  0.5020967   0.42084002  0.03766001  0.46454334 -0.44661132\n",
            "  0.22226368  0.0327     -0.43126     0.00774    -0.15634833  0.3885993\n",
            " -0.38001335 -0.13208102  0.22859664 -0.39621338  0.24020332  0.41949666\n",
            " -0.6473667  -0.11796334  0.300212   -0.04890667  0.19057    -0.65398\n",
            " -0.09819666  0.09049634 -0.12865366 -0.19084066 -0.30180568  0.07661999\n",
            "  0.03418794 -0.029667   -0.14523333 -0.23192567  0.09882667  0.43341336\n",
            "  0.047808   -0.09808999  0.26746067 -0.234358    0.12239435  0.81658\n",
            " -0.4490467   0.5518833  -0.29156667 -0.33961263  0.30956998  0.06785334\n",
            " -0.4310867   0.300855    0.265036    0.6470366  -0.7136433   0.01400334\n",
            "  0.10547134 -0.07894     0.25629333 -0.21767335  0.250195   -0.59736663\n",
            "  0.2866867  -0.05228667  0.23764335 -0.49035335 -0.45085332 -0.51667\n",
            " -0.01609633 -0.32716    -0.22492333 -0.47330332 -0.15200032  0.20181668\n",
            " -0.24229133  0.18925601 -0.060564   -0.21973099  0.24457999 -0.28706333\n",
            "  0.66340667  0.27743337 -0.49113    -0.26614666 -0.22016667  0.50276667\n",
            "  0.48637667  0.28844333 -0.2935419   0.45673665  0.23382999  0.5161\n",
            " -0.19783266 -0.18264268  0.019692   -0.013066    0.08293099  0.02575266\n",
            " -0.05760333 -0.30384     0.28910998 -0.30737334 -0.07102667 -0.11787966\n",
            " -0.35104668 -0.23236667  0.15019666 -0.01766733  0.6193733   0.16082667\n",
            " -0.11402833  0.14723666 -0.69580334 -0.23911469  0.234387    0.35806334\n",
            "  1.4951667  -0.21275432 -0.30564666  0.17912032 -0.31634    -0.6953034\n",
            "  0.20261668  0.47446966  0.2579     -0.62838    -0.13436668 -0.18600166\n",
            " -0.14682834  0.03335    -0.06864333 -0.24147433 -0.15195    -0.13681023\n",
            " -0.05313335  0.34631002]\n",
            "Shape:     (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Розмірність вектора документа не залежить від кількості слів у ньому:"
      ],
      "metadata": {
        "id": "ef2tBQytUvkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    \"Hello world\",\n",
        "    \"You can try the best you can. The best you can is good enough.\",\n",
        "]\n",
        "print(\"Розмір    Документ\")\n",
        "print(\"-\" * 80)\n",
        "for s in tests:\n",
        "    shape = bag_of_embeddings(\"Hello world!\", glove).shape\n",
        "    print(f\"{shape}    {s}\")"
      ],
      "metadata": {
        "id": "DNvRbFEoUz4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9d83d0-4441-42d8-8bed-ed5a6b435e8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір    Документ\n",
            "--------------------------------------------------------------------------------\n",
            "(200,)    Hello world\n",
            "(200,)    You can try the best you can. The best you can is good enough.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.checkpoint(\"`Hello world` centroid\", bag_of_embeddings(\"Hello world!\", glove).mean())"
      ],
      "metadata": {
        "id": "xKrsXe7DVPR8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "05f21b18-822b-4b4a-a886-2829747c6ce7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0046237493'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRL0YDoop_iu"
      },
      "source": [
        "# Векторизація всього корпусу\n",
        "\n",
        "Наступна операція може зайняти пару хвилин:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3YZqlcOvkV3"
      },
      "source": [
        "!pip install --quiet datasets"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QWs_M95p_iu"
      },
      "source": [
        "import datasets\n",
        "imdb = datasets.load_dataset(\"imdb\")\n",
        "\n",
        "valid_data = imdb[\"test\"].shuffle(seed=1).filter(lambda x, i: i < 2000, with_indices=True)  # take 2000 random rows for validation\n",
        "train_data = imdb[\"train\"].shuffle(seed=2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def vectorize_dataset(dataset: datasets.Dataset) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Векторізує весь датасет у представлення bag-of-embeddings.\n",
        "\n",
        "    Повертає матрицю ознак X та вектор класів y.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    for doc in tqdm(dataset):\n",
        "        doc_vector = bag_of_embeddings(doc[\"text\"], glove)\n",
        "        X.append(doc_vector)\n",
        "\n",
        "    X = np.stack(X)\n",
        "    y = np.array(dataset[\"label\"])\n",
        "    return (X, y)"
      ],
      "metadata": {
        "id": "uMDsl8LPUfZ2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxA_y-PPp_iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db7a1cf-14f8-4f33-cb2d-6f68ab20988d"
      },
      "source": [
        "X_train_boe, y_train_boe = vectorize_dataset(train_data)\n",
        "X_valid_boe, y_valid_boe = vectorize_dataset(valid_data)\n",
        "lab.checkpoint(\"Vectorized dataset shape\", X_train_boe.shape)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [00:49<00:00, 507.42it/s]\n",
            "100%|██████████| 2000/2000 [00:02<00:00, 829.66it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FK-cMukZZqUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xORrcb8ap_iv"
      },
      "source": [
        "## Logistic regression + Bag-of-Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Штучно обмежимо кількість тренувальних прикладів цим значенням.\n",
        "# Так ми емулюємо ситуацію, коли в нас мало тренувальних даних.\n",
        "TRAIN_SIZE = 500"
      ],
      "metadata": {
        "id": "43OKsPYeWlw8"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iftv_Jq9p_iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cda75a7-2979-442c-80d0-2f960f22633e"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Тренуємо логістичну регресію\n",
        "logreg = LogisticRegression(solver=\"liblinear\")\n",
        "\n",
        "logreg.fit(X_train_boe[:TRAIN_SIZE,], y_train_boe[:TRAIN_SIZE,])\n",
        "logreg_acc = logreg.score(X_valid_boe, y_valid_boe)\n",
        "lab.checkpoint(f\"LogReg + BoE accuracy on {TRAIN_SIZE}\", logreg_acc)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7325"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression + TF-IDF\n",
        "\n",
        "Натренуємо для порівняння модель на TF-IDF bag-of-ngrams ознаках. Тренувальні дані точнісінько такі, як і у моделі bag-of-embeddings. Але як щодо якості?\n"
      ],
      "metadata": {
        "id": "vJBKiOWBfnr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X_train_bow = vectorizer.fit_transform(train_data[:TRAIN_SIZE][\"text\"])\n",
        "\n",
        "model_tfidf = LogisticRegression(solver='liblinear', C=0.2, penalty=\"l1\")\n",
        "model_tfidf.fit(X_train_bow, train_data[\"label\"][:TRAIN_SIZE])\n",
        "\n",
        "\n",
        "X_valid_bow = vectorizer.transform(valid_data[\"text\"])\n",
        "y_valid_bow = valid_data[\"label\"]\n",
        "tfidf_acc = model_tfidf.score(X_valid_bow, y_valid_bow)\n",
        "lab.checkpoint(f\"LogReg + TF-IDF accuracy on {TRAIN_SIZE}\", tfidf_acc)"
      ],
      "metadata": {
        "id": "K-I-Ij3_Gzbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1084a2-4700-49d1-ea4c-4bd2ee6255e0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5035"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання\n",
        "\n",
        "Перетренуйте моделі на різних розмірах `TRAIN_SIZE`. Спробуйте кілька значень. Зверніть увагу, як різницю між моделями змінюється в залежності від `TRAIN_SIZE`.\n",
        "\n",
        "❗ Результат (посилання на ваш Google Colab або PDF) відправте на пошту oleksii.o.syvokon@lpnu.ua ❗"
      ],
      "metadata": {
        "id": "UhrxAf4IgT5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для `TRAIN_SIZE`= 1000"
      ],
      "metadata": {
        "id": "iUMTSIkK_2LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Logistic regression + Bag-of-Embeddings\", logreg_acc)\n",
        "print(\"Accuracy Logistic regression + TF-IDF\", tfidf_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P7BGByu_40_",
        "outputId": "b01c5073-1f3e-4666-997f-fc62d524abd7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic regression + Bag-of-Embeddings 0.773\n",
            "Accuracy Logistic regression + TF-IDF 0.5035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для `TRAIN_SIZE`= 2500"
      ],
      "metadata": {
        "id": "mxzqfS35_mp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Logistic regression + Bag-of-Embeddings\", logreg_acc)\n",
        "print(\"Accuracy Logistic regression + TF-IDF\", tfidf_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9VwZC2j_l8b",
        "outputId": "b0dd75ee-7241-44f1-82ff-1f3262546134"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic regression + Bag-of-Embeddings 0.7935\n",
            "Accuracy Logistic regression + TF-IDF 0.656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для `TRAIN_SIZE`= 5000"
      ],
      "metadata": {
        "id": "eAMChFDB_ya_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Logistic regression + Bag-of-Embeddings\", logreg_acc)\n",
        "print(\"Accuracy Logistic regression + TF-IDF\", tfidf_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa__tlkj_xDJ",
        "outputId": "7c24f234-2ec2-4d0c-fc4b-d9c381089dad"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic regression + Bag-of-Embeddings 0.803\n",
            "Accuracy Logistic regression + TF-IDF 0.7415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для `TRAIN_SIZE`= 10000"
      ],
      "metadata": {
        "id": "YwyyXu9l_5fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Logistic regression + Bag-of-Embeddings\", logreg_acc)\n",
        "print(\"Accuracy Logistic regression + TF-IDF\", tfidf_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vNvYFkiAB28",
        "outputId": "8678f537-fa3b-483f-8b74-35813560b2f3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic regression + Bag-of-Embeddings 0.805\n",
            "Accuracy Logistic regression + TF-IDF 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для `TRAIN_SIZE`= 20000"
      ],
      "metadata": {
        "id": "wXLCbLr3_9cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Logistic regression + Bag-of-Embeddings\", logreg_acc)\n",
        "print(\"Accuracy Logistic regression + TF-IDF\", tfidf_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BV0jqxJACH-",
        "outputId": "f645f9ec-b673-4d8e-ad4b-56989cf87359"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic regression + Bag-of-Embeddings 0.8135\n",
            "Accuracy Logistic regression + TF-IDF 0.8295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для `TRAIN_SIZE`= 25000"
      ],
      "metadata": {
        "id": "ethBJOOB__4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Logistic regression + Bag-of-Embeddings\", logreg_acc)\n",
        "print(\"Accuracy Logistic regression + TF-IDF\", tfidf_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsBH3K3xACi6",
        "outputId": "0299d595-d244-45e0-afb4-b161f9c183a5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic regression + Bag-of-Embeddings 0.8135\n",
            "Accuracy Logistic regression + TF-IDF 0.8365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можемо помітити що при використанні Bag-of-Embeddings точність на малих наборах даних значно краща ніж при використанні TF-IDF. Після 20000 регресія з TF-IDF починає давати трішки кращу точність. На малих наборах даних недостатньо прикладів, щоб адекватно навчити TF-IDF, оскільки цей підхід залежить від частоти слів."
      ],
      "metadata": {
        "id": "6w9OV18h_1Yd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVoUZm0lxGds"
      },
      "source": [
        "# Embeddings matrix\n",
        "\n",
        "Досі для доступу до векторів слів ми користувалися бібліотекою `gensim`, яка надавала нам інтерфейс словника (`dict`).\n",
        "\n",
        "Під капотом, вектори слів зберігаються в одній матриці розмірності $|V| \\times d$, де $|V|$ це розмір словника (скільки слів маємо), а $d$ — розмір вектора слова (в цій лабораторній було $d=200$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0a3Cxl9iDBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69d45f8-9c77-4c82-8b55-8389e736fac8"
      },
      "source": [
        "glove.vectors.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VybrpjjOkrrR"
      },
      "source": [
        "В моделях глибинного навчання, як правило, справу мають саме з цією embeddings matrix.\n",
        "\n",
        "Розглянемо два способи отримати вектор потрібного слова з цієї матриці:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZGXRCNrlBde"
      },
      "source": [
        "## Vector-matrix multiplication\n",
        "\n",
        "Перший спосіб, це представити слово з індексом $i$ у вигляді one-hot вектора $o_i$. Тоді ембедінг потрібного слова можна отримати в результаті добутку\n",
        "\n",
        "$$e_i = \\text{E}^\\intercal o_i $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryDrswVlkoUk"
      },
      "source": [
        "import torch\n",
        "\n",
        "embeddings_matrix = torch.tensor(glove.vectors)\n",
        "\n",
        "def embed(token_index: int, embeddings_matrix: torch.tensor) -> torch.tensor:\n",
        "    vocab_size, embed_dim = embeddings_matrix.shape\n",
        "    one_hot = torch.zeros(vocab_size)\n",
        "    one_hot[token_index] = 1\n",
        "    return one_hot @ embeddings_matrix\n",
        "\n",
        "assert torch.allclose(\n",
        "    embed(42, embeddings_matrix),\n",
        "    torch.tensor(glove.vectors[42]))\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0xFJ6DUm6GW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "346048ab-78e4-43d8-e706-ea24491ee610"
      },
      "source": [
        "lab.checkpoint(\"The embedding of one-hot multiplication\",\n",
        "               embed(42, embeddings_matrix).sum())"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tensor(5.3482)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4vqXSL4m2gF"
      },
      "source": [
        "## nn.Embedding\n",
        "\n",
        "В PyTorch, як і в більшості deep learning frameworks, є спеціальна функція, яка повертає вектор з потрібним номером: `torch.nn.Embedding`. Вона імплементована більш ефективно, ніж спосіб з vector-matrix multiplication, тож в більшості випадків користуватися варто саме `nn.Embedding`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A29kVgWvrr9I"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "embeddings = nn.Embedding(num_embeddings=50_000, embedding_dim=200, _weight=embeddings_matrix)\n",
        "indexes = torch.LongTensor([42])\n",
        "embedded = embeddings(indexes)\n",
        "\n",
        "assert np.isclose(embedded.sum().item(), glove.vectors[42].sum())"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTBXxCdutJLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a54420-d6a3-49b1-d340-c464532ab3fb"
      },
      "source": [
        "lab.checkpoint(\"nn.Embeddings\", embedded.sum().item())"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.34816837310791"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Готово!"
      ],
      "metadata": {
        "id": "7U97-goHHZrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lab.answer(\"ALL DONE! 😊\")"
      ],
      "metadata": {
        "id": "ZUariUJ2HiQ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "79724c9f-91c6-4d8a-c90b-18ffb5d52f89"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Відповідь правильна ✅\n",
            "💪\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ALL DONE! 😊'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}