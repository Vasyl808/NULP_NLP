{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasyl808/NULP_NLP/blob/main/rnn_quest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6f0f1e",
      "metadata": {
        "id": "ee6f0f1e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import json\n",
        "from typing import Dict, Union, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5419ddc1",
      "metadata": {
        "id": "5419ddc1"
      },
      "outputs": [],
      "source": [
        "def load_parameters(base_path: str) -> Dict[str, Union[List, torch.tensor]]:\n",
        "    file_names: Dict[str, str] = {\n",
        "        \"vocab\": \"vocab.json\",\n",
        "        \"embeddings\": \"embedding.weight.json\",\n",
        "        \"W_h\": \"W_h.weight.json\",\n",
        "        \"W_y\": \"W_y.weight.json\",\n",
        "        \"U_h\": \"U_h.weight.json\",\n",
        "        \"W_h_bias\": \"W_h.bias.json\"\n",
        "    }\n",
        "\n",
        "    parameters: Dict[str, Union[List, torch.tensor]] = {}\n",
        "\n",
        "    for param_name, file_name in file_names.items():\n",
        "        with open(f\"{base_path}/{file_name}\", \"r\", encoding=\"utf-8\") as f:\n",
        "            if param_name == \"vocab\":\n",
        "                parameters[param_name] = json.load(f)\n",
        "            else:\n",
        "                parameters[param_name] = torch.tensor(json.load(f))\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0efdc979",
      "metadata": {
        "id": "0efdc979",
        "outputId": "91ca00ee-804e-44d1-bb6b-d211631ecaf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'vocab': ['\\t',\n",
              "  '\\n',\n",
              "  '\\x0b',\n",
              "  '\\x0c',\n",
              "  '\\r',\n",
              "  ' ',\n",
              "  '!',\n",
              "  '\"',\n",
              "  '#',\n",
              "  '$',\n",
              "  '%',\n",
              "  '&',\n",
              "  \"'\",\n",
              "  '(',\n",
              "  ')',\n",
              "  '*',\n",
              "  '+',\n",
              "  ',',\n",
              "  '-',\n",
              "  '.',\n",
              "  '/',\n",
              "  '0',\n",
              "  '1',\n",
              "  '2',\n",
              "  '3',\n",
              "  '4',\n",
              "  '5',\n",
              "  '6',\n",
              "  '7',\n",
              "  '8',\n",
              "  '9',\n",
              "  ':',\n",
              "  ';',\n",
              "  '<',\n",
              "  '=',\n",
              "  '>',\n",
              "  '?',\n",
              "  '@',\n",
              "  'A',\n",
              "  'B',\n",
              "  'C',\n",
              "  'D',\n",
              "  'E',\n",
              "  'F',\n",
              "  'G',\n",
              "  'H',\n",
              "  'I',\n",
              "  'J',\n",
              "  'K',\n",
              "  'L',\n",
              "  'M',\n",
              "  'N',\n",
              "  'O',\n",
              "  'P',\n",
              "  'Q',\n",
              "  'R',\n",
              "  'S',\n",
              "  'T',\n",
              "  'U',\n",
              "  'V',\n",
              "  'W',\n",
              "  'X',\n",
              "  'Y',\n",
              "  'Z',\n",
              "  '[',\n",
              "  '\\\\',\n",
              "  ']',\n",
              "  '^',\n",
              "  '_',\n",
              "  '`',\n",
              "  'a',\n",
              "  'b',\n",
              "  'c',\n",
              "  'd',\n",
              "  'e',\n",
              "  'f',\n",
              "  'g',\n",
              "  'h',\n",
              "  'i',\n",
              "  'j',\n",
              "  'k',\n",
              "  'l',\n",
              "  'm',\n",
              "  'n',\n",
              "  'o',\n",
              "  'p',\n",
              "  'q',\n",
              "  'r',\n",
              "  's',\n",
              "  't',\n",
              "  'u',\n",
              "  'v',\n",
              "  'w',\n",
              "  'x',\n",
              "  'y',\n",
              "  'z',\n",
              "  '{',\n",
              "  '|',\n",
              "  '}',\n",
              "  '~',\n",
              "  'Н',\n",
              "  'а',\n",
              "  'б',\n",
              "  'в',\n",
              "  'г',\n",
              "  'д',\n",
              "  'е',\n",
              "  'ж',\n",
              "  'з',\n",
              "  'и',\n",
              "  'й',\n",
              "  'к',\n",
              "  'л',\n",
              "  'м',\n",
              "  'н',\n",
              "  'о',\n",
              "  'п',\n",
              "  'р',\n",
              "  'с',\n",
              "  'т',\n",
              "  'у',\n",
              "  'ф',\n",
              "  'х',\n",
              "  'ц',\n",
              "  'ч',\n",
              "  'ш',\n",
              "  'щ',\n",
              "  'ь',\n",
              "  'ю',\n",
              "  'я',\n",
              "  'є',\n",
              "  'і',\n",
              "  'ї'],\n",
              " 'embeddings': tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.3399,  0.7200,  0.4114],\n",
              "         [ 1.9312,  1.0119, -1.4364,  ...,  0.5655,  0.5058,  0.2225],\n",
              "         [-0.6855,  0.5636, -1.5072,  ...,  0.8541, -0.4901, -0.3595],\n",
              "         ...,\n",
              "         [-0.7694,  0.7945, -0.1317,  ...,  0.2118,  1.0113,  0.4264],\n",
              "         [-0.1265, -2.2684,  1.5827,  ...,  2.4251, -1.1458,  1.2681],\n",
              "         [ 0.2754,  2.2441,  0.5156,  ...,  1.5713, -1.2235, -0.6678]]),\n",
              " 'W_h': tensor([[ 0.0030, -0.0452, -0.1279,  ...,  0.0328,  0.1194,  0.0608],\n",
              "         [-0.0085, -0.0764, -0.0650,  ..., -0.0565,  0.0794,  0.0440],\n",
              "         [ 0.0248,  0.0889,  0.0814,  ...,  0.0812,  0.0521,  0.0621],\n",
              "         ...,\n",
              "         [ 0.0968,  0.0974,  0.0645,  ..., -0.0799,  0.0117, -0.0285],\n",
              "         [ 0.0516,  0.0287, -0.0298,  ...,  0.0251, -0.0325, -0.0826],\n",
              "         [ 0.0425, -0.0003, -0.0349,  ..., -0.0990,  0.0512,  0.0767]]),\n",
              " 'W_y': tensor([[ 0.0015, -0.0211,  0.0120,  ..., -0.0237, -0.0556,  0.0339],\n",
              "         [ 0.0612, -0.0164, -0.0186,  ...,  0.0486, -0.0251, -0.0211],\n",
              "         [-0.0197,  0.0434, -0.0143,  ...,  0.0312, -0.0512,  0.0732],\n",
              "         ...,\n",
              "         [ 0.0534,  0.0402, -0.0029,  ..., -0.0492, -0.0109,  0.0356],\n",
              "         [-0.0591, -0.0549,  0.0476,  ...,  0.0312,  0.0265, -0.0514],\n",
              "         [ 0.0454,  0.0042, -0.0049,  ...,  0.0683,  0.0321, -0.0122]]),\n",
              " 'U_h': tensor([[ 0.0889, -0.0379,  0.0009,  ...,  0.0210, -0.0418,  0.0365],\n",
              "         [ 0.0932,  0.0270,  0.0761,  ...,  0.0572,  0.0674,  0.0563],\n",
              "         [ 0.0790, -0.0194,  0.1029,  ...,  0.0664, -0.0367,  0.0520],\n",
              "         ...,\n",
              "         [-0.0201, -0.0747,  0.0354,  ..., -0.0258,  0.0589,  0.0235],\n",
              "         [-0.0072,  0.0564, -0.0256,  ...,  0.0122,  0.0790, -0.0000],\n",
              "         [-0.0229,  0.0258, -0.0555,  ...,  0.0354,  0.0112, -0.0616]]),\n",
              " 'W_h_bias': tensor([-0.0099,  0.0518, -0.0546,  0.0025, -0.0203, -0.0004,  0.0362,  0.0501,\n",
              "         -0.0378, -0.0071, -0.0079, -0.0034, -0.0463, -0.0492,  0.0617, -0.0681,\n",
              "         -0.0123,  0.1100,  0.0829, -0.0900, -0.0211,  0.0524,  0.0655,  0.0299,\n",
              "         -0.0416, -0.1014,  0.0661, -0.0065, -0.0697, -0.0656,  0.0285,  0.0791,\n",
              "         -0.0394, -0.0275,  0.0931,  0.0141, -0.0739, -0.0211,  0.0769, -0.0401,\n",
              "          0.0939,  0.0336, -0.0425,  0.0604,  0.0841,  0.0777,  0.0641, -0.0200,\n",
              "          0.0792,  0.0135,  0.0266,  0.0299,  0.0814,  0.0381, -0.0174, -0.0006,\n",
              "         -0.0634,  0.0414, -0.0561, -0.0006, -0.0124, -0.0309, -0.0425,  0.0485,\n",
              "          0.0833, -0.1075,  0.0199, -0.0201,  0.0940, -0.0821, -0.0338, -0.0790,\n",
              "         -0.0573,  0.0890,  0.0656,  0.0496, -0.0440, -0.0660,  0.1021, -0.0150,\n",
              "          0.0108,  0.0890,  0.0411,  0.0099, -0.0031, -0.0331, -0.0027, -0.0147,\n",
              "         -0.1357,  0.0394,  0.0932,  0.0476,  0.0773, -0.0659, -0.0017,  0.0354,\n",
              "         -0.0545, -0.0810,  0.0495, -0.0588, -0.0494,  0.0067, -0.0815, -0.0788,\n",
              "          0.1161, -0.0794, -0.0417,  0.0548, -0.0481,  0.1115,  0.0216,  0.1231,\n",
              "         -0.0586,  0.0518,  0.0371,  0.0154,  0.0564, -0.0492,  0.0094, -0.0635,\n",
              "          0.0417,  0.0082, -0.0958,  0.0628, -0.0847, -0.0094,  0.0513, -0.0276,\n",
              "         -0.1204, -0.0927, -0.0474,  0.0579, -0.0453,  0.0681, -0.0870, -0.1081,\n",
              "         -0.0150,  0.0734, -0.0785, -0.0191,  0.0446,  0.1005, -0.0485,  0.0717,\n",
              "         -0.0493, -0.0386, -0.0692,  0.0244,  0.0299,  0.0602, -0.0758,  0.0507,\n",
              "          0.0109, -0.1001, -0.0056,  0.0665,  0.0687, -0.0446, -0.0867, -0.0868])}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path: str = r\"D:\\deepfake_detection_model\\d7071db0908e\"\n",
        "\n",
        "parms = load_parameters(path)\n",
        "parms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311c0076",
      "metadata": {
        "id": "311c0076"
      },
      "outputs": [],
      "source": [
        "class ElmanRNN(nn.Module):\n",
        "    def __init__(self, embeddings, W_h, W_y, U_h, W_h_bias, vocab):\n",
        "        super(ElmanRNN, self).__init__()\n",
        "\n",
        "        self.embeddings = nn.Parameter(embeddings)\n",
        "        self.W_h = nn.Parameter(W_h)\n",
        "        self.W_y = nn.Parameter(W_y)\n",
        "        self.U_h = nn.Parameter(U_h)\n",
        "        self.W_h_bias = nn.Parameter(W_h_bias)\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.hidden_size = W_h.shape[0]\n",
        "\n",
        "    def forward(self, input_char: str, hidden_state: torch.tensor):\n",
        "        embedded_input = self.embeddings[self.vocab.index(input_char)]\n",
        "\n",
        "        hidden_state = torch.tanh(self.W_h @ embedded_input + self.W_h_bias + self.U_h @ hidden_state)\n",
        "\n",
        "        output_logits = self.W_y @ hidden_state\n",
        "\n",
        "        return output_logits, hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4f8212",
      "metadata": {
        "id": "cd4f8212"
      },
      "outputs": [],
      "source": [
        "def decode_message(rnn_model: nn.Module):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    hidden_state = torch.zeros(rnn_model.hidden_size, device=device)\n",
        "    decoded_message = \"\"\n",
        "    current_char = \"[\"\n",
        "\n",
        "    while True:\n",
        "        output_logits, hidden_state = rnn_model(current_char, hidden_state)\n",
        "\n",
        "        next_char_idx = torch.argmax(output_logits).item()\n",
        "        current_char = rnn_model.vocab[next_char_idx]\n",
        "\n",
        "        if current_char == \"]\":\n",
        "            break\n",
        "\n",
        "        decoded_message += current_char\n",
        "\n",
        "    return decoded_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761fd4ec",
      "metadata": {
        "id": "761fd4ec"
      },
      "outputs": [],
      "source": [
        "model = ElmanRNN(**parms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e69cc4ca",
      "metadata": {
        "id": "e69cc4ca",
        "outputId": "80b9845d-1cfd-4256-e201-c6cb18aa2790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Назва виконавця: https://www.youtube.com/watch?v=dtSmUF0vMKE'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decode_message(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bdb5703",
      "metadata": {
        "id": "1bdb5703",
        "outputId": "0b5d841d-dc47-409c-b016-14e53db1d044"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c000b35",
      "metadata": {
        "id": "1c000b35",
        "outputId": "f1c4ba4c-febc-4aed-987a-f5fce70dd79a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "892eda30",
      "metadata": {
        "id": "892eda30",
        "outputId": "b430220e-8f60-4bdd-a876-547cdface623"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([133, 128])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e34676",
      "metadata": {
        "id": "e0e34676"
      },
      "outputs": [],
      "source": [
        "def message_to_indices(message: str, vocab: List):\n",
        "    return [vocab.index(char) for char in message]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa556237",
      "metadata": {
        "id": "aa556237"
      },
      "outputs": [],
      "source": [
        "def train_model(model: nn.Module, message: str, vocab: List, epochs: int = 1000, learning_rate: float = 0.01):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f'Device: {device}')\n",
        "\n",
        "    model.to(device)\n",
        "    params_to_train = [param for name, param in model.named_parameters() if 'embedding' not in name]\n",
        "\n",
        "    optimizer = optim.Adam(params_to_train, lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    indices = message_to_indices(message, vocab)\n",
        "    hidden_state = torch.zeros(model.hidden_size, device=device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss = 0\n",
        "        for i in range(len(indices) - 1):\n",
        "            input_char = vocab[indices[i]]\n",
        "            target_char = vocab[indices[i + 1]]\n",
        "\n",
        "            hidden_state_copy = hidden_state.clone().detach()\n",
        "            output_logits, hidden_state = model(input_char, hidden_state_copy)\n",
        "            target_idx = vocab.index(target_char)\n",
        "\n",
        "            loss = criterion(output_logits.view(1, -1), torch.tensor([target_idx], device=device))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {total_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75cca88",
      "metadata": {
        "id": "d75cca88"
      },
      "outputs": [],
      "source": [
        "message = \"[Attention Is All You Need]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95e20f56",
      "metadata": {
        "id": "95e20f56",
        "outputId": "1e14a751-868e-4371-d690-77933944e13d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Epoch 0, Loss: 176.5772466659546\n",
            "Epoch 100, Loss: 0.006402288526714983\n",
            "Epoch 200, Loss: 0.0034013375061476836\n",
            "Epoch 300, Loss: 0.0022314672353331844\n",
            "Epoch 400, Loss: 0.0016081844585187355\n",
            "Epoch 500, Loss: 0.0012261473214039142\n",
            "Epoch 600, Loss: 0.0009729614956768273\n",
            "Epoch 700, Loss: 0.0007961823239384103\n",
            "Epoch 800, Loss: 0.000665772336333248\n",
            "Epoch 900, Loss: 0.0005663549918608624\n",
            "Decoded message: Attention Is All You Need\n"
          ]
        }
      ],
      "source": [
        "model = ElmanRNN(**parms)\n",
        "\n",
        "train_model(model, message, parms.get('vocab'))\n",
        "\n",
        "decoded_message = decode_message(model)\n",
        "\n",
        "print(\"Decoded message:\", decoded_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8632c27f",
      "metadata": {
        "id": "8632c27f",
        "outputId": "90ebad3f-dbfd-432e-dd77-06adc957b6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter name: embeddings\n",
            "Parameter shape: torch.Size([133, 128])\n",
            "Parameter values: Parameter containing:\n",
            "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.3399,  0.7200,  0.4114],\n",
            "        [ 1.9312,  1.0119, -1.4364,  ...,  0.5655,  0.5058,  0.2225],\n",
            "        [-0.6855,  0.5636, -1.5072,  ...,  0.8541, -0.4901, -0.3595],\n",
            "        ...,\n",
            "        [-0.7694,  0.7945, -0.1317,  ...,  0.2118,  1.0113,  0.4264],\n",
            "        [-0.1265, -2.2684,  1.5827,  ...,  2.4251, -1.1458,  1.2681],\n",
            "        [ 0.2754,  2.2441,  0.5156,  ...,  1.5713, -1.2235, -0.6678]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "----------------------------------------\n",
            "Parameter name: W_h\n",
            "Parameter shape: torch.Size([160, 128])\n",
            "Parameter values: Parameter containing:\n",
            "tensor([[ 0.0777,  0.0500, -0.0421,  ..., -0.0682,  0.0316, -0.0183],\n",
            "        [-0.0734,  0.0317, -0.0095,  ..., -0.1492,  0.1381, -0.0488],\n",
            "        [ 0.0033,  0.0045, -0.0050,  ...,  0.1789,  0.1398,  0.1248],\n",
            "        ...,\n",
            "        [ 0.0381,  0.1209,  0.1669,  ..., -0.0720,  0.0688, -0.0548],\n",
            "        [ 0.0490, -0.0647, -0.1066,  ...,  0.1311,  0.0641, -0.0225],\n",
            "        [ 0.0630, -0.0114,  0.0393,  ..., -0.1446, -0.0466,  0.0667]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "----------------------------------------\n",
            "Parameter name: W_y\n",
            "Parameter shape: torch.Size([133, 160])\n",
            "Parameter values: Parameter containing:\n",
            "tensor([[-0.1274, -0.1514, -0.0386,  ..., -0.1270, -0.1810,  0.1503],\n",
            "        [-0.0898, -0.1411,  0.0500,  ..., -0.0576, -0.1445,  0.1173],\n",
            "        [-0.1638, -0.1043,  0.0535,  ..., -0.0151, -0.1810,  0.1037],\n",
            "        ...,\n",
            "        [-0.1031, -0.0823, -0.0298,  ..., -0.1413, -0.1301,  0.1882],\n",
            "        [-0.1973, -0.1926,  0.0587,  ..., -0.0477, -0.0944,  0.1092],\n",
            "        [-0.1070, -0.1270, -0.0322,  ..., -0.0599, -0.0881,  0.0998]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "----------------------------------------\n",
            "Parameter name: U_h\n",
            "Parameter shape: torch.Size([160, 160])\n",
            "Parameter values: Parameter containing:\n",
            "tensor([[ 0.1064, -0.1334,  0.1062,  ...,  0.0658,  0.0223,  0.0128],\n",
            "        [-0.0440, -0.0861,  0.1637,  ...,  0.0699,  0.0269, -0.0149],\n",
            "        [ 0.1789,  0.1111,  0.1472,  ...,  0.0586, -0.0761,  0.1148],\n",
            "        ...,\n",
            "        [-0.1643, -0.1727,  0.1302,  ..., -0.1419,  0.0720, -0.0486],\n",
            "        [ 0.1113, -0.0260, -0.1154,  ...,  0.1296,  0.0904,  0.0212],\n",
            "        [ 0.0315, -0.0686,  0.0008,  ...,  0.1117, -0.0788, -0.1608]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "----------------------------------------\n",
            "Parameter name: W_h_bias\n",
            "Parameter shape: torch.Size([160])\n",
            "Parameter values: Parameter containing:\n",
            "tensor([ 0.0214,  0.1392,  0.0163,  0.0225,  0.0224, -0.0557, -0.0299,  0.1512,\n",
            "        -0.0901, -0.0715, -0.0796, -0.0228, -0.1020,  0.0458,  0.1297, -0.1163,\n",
            "        -0.0930,  0.0992,  0.0142, -0.1727, -0.0102,  0.1028,  0.0704,  0.0543,\n",
            "         0.0272, -0.0529, -0.0073, -0.0649, -0.0389, -0.0237, -0.0316,  0.1505,\n",
            "         0.0258, -0.0665, -0.0047,  0.0437, -0.0069, -0.1045,  0.2026, -0.0999,\n",
            "         0.0962, -0.0273,  0.0353,  0.0984,  0.0308,  0.1346,  0.1542,  0.0582,\n",
            "        -0.0229, -0.0731,  0.0827,  0.1316,  0.1512,  0.1035, -0.0659,  0.0944,\n",
            "        -0.1366,  0.1079,  0.0204,  0.1055,  0.0816,  0.0322, -0.0197,  0.0105,\n",
            "         0.0575, -0.1676,  0.1113, -0.0890,  0.1785, -0.0557, -0.0432, -0.0010,\n",
            "        -0.0879,  0.0329,  0.1427,  0.1538, -0.0793,  0.0339,  0.1805, -0.1021,\n",
            "        -0.0182, -0.0138,  0.1167,  0.0524, -0.0455,  0.0254,  0.0315, -0.0604,\n",
            "        -0.1690,  0.0008,  0.0098,  0.0971,  0.1544, -0.0788,  0.0588, -0.0503,\n",
            "        -0.0329, -0.0296,  0.0564,  0.0214, -0.0729,  0.0894, -0.1752, -0.1289,\n",
            "         0.1357, -0.2150, -0.1191, -0.0225,  0.0306,  0.2064, -0.0837,  0.1627,\n",
            "         0.0133,  0.1220,  0.0930, -0.0406,  0.1447, -0.0706,  0.0928,  0.0134,\n",
            "        -0.0167, -0.0257, -0.0421,  0.1473, -0.1739,  0.0768, -0.0206,  0.0517,\n",
            "        -0.1810, -0.0700, -0.1305, -0.0347, -0.1149,  0.0299, -0.1115, -0.0521,\n",
            "        -0.0874, -0.0206, -0.0497, -0.0297, -0.0691,  0.2054,  0.0111,  0.1727,\n",
            "         0.0338,  0.0279, -0.1889,  0.1155, -0.0129,  0.1501, -0.1638, -0.0016,\n",
            "         0.0829, -0.1832,  0.0219, -0.0297, -0.0011,  0.0533, -0.0289, -0.1341],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}\")\n",
        "    print(f\"Parameter shape: {param.shape}\")\n",
        "    print(f\"Parameter values: {param}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f61df8c",
      "metadata": {
        "id": "4f61df8c",
        "outputId": "d4a26f69-4e02-42de-a494-89d660f2d4c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "160"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b9b90f0",
      "metadata": {
        "id": "0b9b90f0",
        "outputId": "b4a9f8e5-8c9f-445e-e01d-b26867f5fe01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([133, 128])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3573efa6",
      "metadata": {
        "id": "3573efa6",
        "outputId": "fa5f61bc-3269-4d20-9709-6941ea82e3ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd70435",
      "metadata": {
        "id": "edd70435"
      },
      "outputs": [],
      "source": [
        "def save_tensor_to_json(tensor: torch.tensor, file_path: str):\n",
        "    tensor_list = tensor.tolist()\n",
        "    with open(file_path, 'w') as f:\n",
        "        json.dump(tensor_list, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e14210",
      "metadata": {
        "id": "80e14210"
      },
      "outputs": [],
      "source": [
        "params_to_save: Dict[str, str] = {\n",
        "    \"W_h\": \"W_h.my.weight.json\",\n",
        "    \"W_y\": \"W_y.my.weight.json\",\n",
        "    \"U_h\": \"U_h.my.weight.json\",\n",
        "    \"W_h_bias\": \"W_h.my.bias.json\"\n",
        "}\n",
        "\n",
        "\n",
        "for param_name, file_path in params_to_save.items():\n",
        "    tensor = getattr(model, param_name)\n",
        "\n",
        "    save_tensor_to_json(tensor, file_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}